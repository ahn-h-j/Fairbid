# 비동기 RDB 동기화 테스트 Specification

> ⚠️ **이 문서는 향후 진행할 테스트의 계획서입니다. 아직 실행 전이며, 실행 후 별도 결과 문서를 작성할 예정입니다.**
> 동기 → @Async → Message Queue 단계별 문제 해결 과정을 테스트로 증명하고, 데이터 기반으로 최적의 아키텍처를 선택한다.

---

## 1. Overview

### Problem Statement

현재 동기 방식의 입찰 플로우에서 **장애 상황 시 데이터 불일치** 문제가 있다:

```
[동기 방식 문제]
1. Redis Lua 스크립트 실행 (트랜잭션 밖, 즉시 반영) ✅
2. RDB write (트랜잭션 안) ❌ 실패
3. HTTP 500 반환

→ 사용자: "입찰 실패했네"
→ Redis: 입찰 반영됨
→ 다른 사용자: WebSocket으로 입찰 알림 받음
→ 결과: Redis-RDB 불일치 + 사용자 혼란
```

### Solution Summary

비동기 전환으로 장애 격리:

```
[비동기 방식]
1. Redis Lua 스크립트 실행 ✅
2. 메시지 큐에 적재 ✅
3. HTTP 200 반환 (즉시 응답)

→ RDB는 Consumer가 비동기로 처리
→ DB 장애 시에도 입찰은 정상 처리
→ 메시지 큐에 남아있다가 복구 후 처리
```

### Success Criteria

| 기준 | 목표 |
|------|------|
| 장애 격리 | DB 다운 시에도 입찰 성공 |
| 복구 가능성 | 앱 재시작 후 미처리 메시지 자동 처리 |
| 최종 정합성 | Eventual Consistency (낙찰 전까지 RDB 동기화) |
| 의사결정 근거 | 테스트 데이터 기반 객관적 선택 |

---

## 2. 테스트 범위

### 2.1 비교 대상 (5가지)

| 단계 | 방식 | 목적 |
|------|------|------|
| Baseline | 동기 (현재) | 문제점 증명 |
| Step 1 | @Async | 비동기 전환, 메모리 기반 한계 증명 |
| Step 2-A | Redis Stream | 기존 인프라 활용 |
| Step 2-B | Kafka | 대규모 시스템 표준 |
| Step 2-C | RabbitMQ | 균형 잡힌 선택지 |

### 2.2 구현 방식

- 기존 프로젝트에서 **구현체 교체**하며 테스트 (락 테스트 때처럼)
- 각 방식별 브랜치 또는 프로파일로 분리
- 동일한 테스트 시나리오로 비교

### 2.3 테스트 환경

- **로컬 Docker** (docker-compose)
- k6 부하 테스트 도구

---

## 3. 판단 기준 (우선순위 순)

### 3.1 1순위: 장애 시 복구 가능성

```
측정 방법:
1. 부하 테스트 중 앱 강제 종료 (docker kill)
2. 재시작 후 미처리 메시지 재처리 여부 확인
3. 최종적으로 Redis-RDB 정합성 확인

성공 기준: 재시작 후 자동 복구 (Eventual Consistency)
- 메시지 유실 없이 브로커에 보존
- 재시작 후 Pending 메시지 처리
- 최종적으로 RDB에 이력 저장 완료
```

### 3.2 2순위: 장애 격리

```
측정 방법:
1. 부하 테스트 중 DB 컨테이너 정지 (docker pause mysql)
2. DB 다운 중 입찰 요청 성공률 측정
3. HTTP 응답 코드 확인 (200 vs 500)

성공 기준: DB 다운 중에도 HTTP 200 반환
```

### 3.3 3순위: 복구 시간

```
측정 방법:
1. 앱 재시작 후 Pending 메시지 처리 시간 측정
2. 정상 상태 복구까지 소요 시간

성공 기준: 재시작 후 자동 복구
```

### 3.4 4순위: 운영 복잡도

```
평가 항목:
- 설정 복잡도 (설정 파일 라인 수)
- 모니터링 용이성 (기본 제공 UI)
- 장애 대응 난이도 (문서화 수준)
- 학습 곡선 (첫 경험 기준)
```

### 3.5 참고: 성능 (동기 vs 비동기 비교에만 사용)

```
동기 vs 비동기 비교 시:
- TPS: 초당 처리량
- p95/p99 latency: 응답 시간

MQ 간 비교에서는 의미 없음:
- 발행만 하고 바로 응답하므로 거의 동일
```

---

## 4. 테스트 시나리오

### Phase 1: 동기 방식 문제점 증명

#### 테스트 1-1: DB 지연 전파

```bash
# DB에 500ms 지연 주입
docker exec mysql tc qdisc add dev eth0 root netem delay 500ms

# k6 부하 테스트 실행
k6 run scripts/bid-load-test.js
```

**측정**: 응답 시간이 500ms+ 증가하는지 확인
**예상**: DB 지연이 응답 시간에 그대로 전파됨

#### 테스트 1-2: DB 다운 시 불일치

```bash
# 부하 테스트 중 DB 정지
docker pause fairbid-mysql

# 5초 후 재개
sleep 5 && docker unpause fairbid-mysql
```

**측정**:
- HTTP 500 에러 발생 건수
- Redis 성공 but RDB 실패 건수 (불일치)

**예상**: Redis에만 반영되고 RDB에는 없는 데이터 발생

---

### Phase 2: @Async 한계 증명

#### 테스트 2-1: 앱 강제 종료 시 유실

```bash
# 부하 테스트 중 앱 강제 종료
docker kill fairbid-app

# 재시작
docker start fairbid-app

# Redis vs RDB 레코드 수 비교
```

**측정**:
- 유실된 메시지 수
- Redis-RDB 불일치 건수

**예상**: 메모리 큐에 있던 메시지 전부 유실

---

### Phase 3: Message Queue 비교

#### 테스트 3-1: 앱 강제 종료 후 복구

```bash
# 각 MQ별로 동일한 테스트 실행
# 부하 테스트 중 앱 강제 종료 → 재시작 → 미처리 메시지 확인
```

**측정** (Redis Stream / Kafka / RabbitMQ 각각):
- 유실된 메시지 수
- Pending 메시지 재처리 여부
- 복구 시간

**예상**: MQ에 따라 복구 특성 차이

#### 테스트 3-2: DB 다운 시 장애 격리

```bash
# DB 다운 상태에서 입찰 요청
docker pause fairbid-mysql

# 입찰 요청 전송
k6 run scripts/bid-simple.js

# DB 복구 후 RDB 동기화 확인
docker unpause fairbid-mysql
```

**측정**:
- DB 다운 중 HTTP 응답 코드 (200 vs 500)
- 복구 후 RDB 동기화 여부

---

## 5. 구현 계획

### 5.1 브랜치 전략

```
main
├── feat/async-test-sync          # 동기 방식 테스트
├── feat/async-test-async         # @Async 구현 + 테스트
├── feat/async-test-redis-stream  # Redis Stream 구현 + 테스트
├── feat/async-test-kafka         # Kafka 구현 + 테스트
└── feat/async-test-rabbitmq      # RabbitMQ 구현 + 테스트
```

### 5.2 구현 순서

```
[Step 1] 테스트 인프라 구성 (1일)
├── docker-compose.test.yml 작성
├── k6 스크립트 작성
└── 측정 스크립트 작성 (Redis vs RDB 비교)

[Step 2] Phase 1 테스트 - 동기 방식 (1일)
├── 테스트 1-1, 1-2 실행
└── 결과 문서화

[Step 3] @Async 구현 + Phase 2 테스트 (1-2일)
├── @Async 적용
├── 테스트 2-1 실행
└── 결과 문서화

[Step 4] Redis Stream 구현 + 테스트 (2일)
├── Redis Stream Consumer 구현
├── Phase 3 테스트 실행
└── 결과 문서화

[Step 5] Kafka 구현 + 테스트 (2-3일)
├── Kafka 설정 + Consumer 구현
├── Phase 3 테스트 실행
└── 결과 문서화

[Step 6] RabbitMQ 구현 + 테스트 (2일)
├── RabbitMQ 설정 + Consumer 구현
├── Phase 3 테스트 실행
└── 결과 문서화

[Step 7] 최종 분석 + 결정 (1일)
├── 비교표 작성
├── 트레이드오프 분석
└── 최종 선택 + 근거 문서화
```

---

## 6. 결과 기록 형식

### 6.1 테스트 결과 문서

```markdown
# Phase N 테스트 결과

## 테스트 환경
- 날짜: YYYY-MM-DD
- 환경: Docker Desktop (Windows)
- 스펙: CPU, RAM

## 테스트 N-M: {테스트명}

### 시나리오
- 부하: N VUs, M 요청
- 장애 주입: {방법}

### 결과
| 지표 | 값 |
|------|---|
| 유실률 | X% |
| ... | ... |

### 스크린샷
{k6 결과 / 로그}

### 분석
{문제점 / 원인 분석}
```

### 6.2 최종 비교표

```markdown
# 아키텍처 비교 결과

| 기준 | 동기 | @Async | Redis Stream | Kafka | RabbitMQ |
|------|------|--------|--------------|-------|----------|
| 데이터 유실률 | N% | N% | N% | N% | N% |
| 장애 격리 | ❌ | ✅ | ✅ | ✅ | ✅ |
| 복구 시간 | N/A | ❌ | Nms | Nms | Nms |
| 운영 복잡도 | 낮음 | 낮음 | 낮음 | 높음 | 중간 |

## 최종 선택: {선택}

### 선택 근거
1. ...
2. ...

### 제외 사유
- {옵션}: {사유}
```

---

## 7. 제약사항 및 Trade-offs

### 7.1 의도적 제외

| 제외 항목 | 사유 |
|----------|------|
| 성능 최적화 | 이미 TPS 1,000 처리 가능, 성능은 문제가 아님 |
| 분산 환경 테스트 | 로컬 Docker로 단일 노드만 테스트 |
| 장기 안정성 테스트 | 포폴 목적상 단기 테스트로 충분 |

### 7.2 학습 비용 고려

- Kafka/RabbitMQ 첫 경험
- 학습 시간이 구현 시간에 포함됨
- 이것 자체가 포트폴리오 가치 (새 기술 습득 과정)

---

## 8. 포트폴리오 스토리라인

### 8.1 전체 흐름

```
[문제 발견]
동기 방식에서 DB 장애 시 Redis-RDB 불일치 발생
→ 테스트로 증명

[1차 해결 시도: @Async]
비동기 전환으로 응답 시간 분리 성공
But 앱 재시작 시 메모리 큐 유실
→ 테스트로 한계 증명

[2차 해결: Message Queue 도입]
3가지 옵션 비교 (Redis Stream / Kafka / RabbitMQ)
→ 테스트 데이터 기반 객관적 선택

[결론]
"왜 이 기술을 선택했는가?"에 대한 명확한 답변 가능
오버엔지니어링 없이 문제에 적합한 기술 선택
```

### 8.2 핵심 의사결정: 유실률 0% vs Eventual Consistency

테스트 설계 과정에서 **"유실률 0%가 정말 필요한가?"** 라는 질문이 나왔다.

#### 기존 구조 분석

```
입찰 처리: Redis (Lua 스크립트, 실시간 검증)
현재가 저장: Redis (Source of Truth)
낙찰자 결정: RDB (bidRepository.findTop2ByAuctionId)
              ↑
              불일치!
```

- 입찰 검증과 현재가는 **Redis 기준**
- 낙찰자 결정만 **RDB 기준** → 아키텍처 불일치
- RDB 유실 시 낙찰자 결정 불가 → 유실률 0% 강제

#### 트레이드오프 분석

| 접근법 | 장점 | 단점 |
|--------|------|------|
| 유실률 0% 추구 | 데이터 안정성 | 오버엔지니어링, 복잡한 복구 로직 |
| Eventual Consistency | 아키텍처 단순화, 유연성 | 일시적 불일치 허용 필요 |

#### 결정: Redis를 Single Source of Truth로

```
[변경 전]
Redis(입찰) → RDB(낙찰자) → 불일치 가능 → 0% 필수

[변경 후]
Redis(입찰) → Redis(낙찰자) → 일관성 → Eventual OK
```

**근거**:
1. 이미 입찰의 핵심 로직(검증, 현재가)은 Redis에서 처리
2. 낙찰자만 RDB에서 결정하는 건 아키텍처적 불일치
3. Redis 기준으로 통일하면 RDB는 순수하게 이력 백업 역할
4. "0%를 맹목적으로 추구"하는 대신 **도메인에 맞는 트레이드오프 선택**

**관련 이슈**: [#58 낙찰자 결정 기준을 RDB에서 Redis로 변경](https://github.com/ahn-h-j/Fairbid/issues/58)

#### 포폴에서 어필할 포인트

> "유실률 0%라는 숫자에 집착하지 않고, 도메인 요구사항을 분석해서 적절한 수준의 일관성을 선택했습니다.
> 모든 시스템이 Strong Consistency를 필요로 하지 않으며, 트레이드오프를 이해하고 상황에 맞게 선택하는 것이 중요합니다."

### 8.3 데이터 조회 정책

**"RDB 동기화 지연이 UX에 영향을 주는가?"**에 대한 분석 결과:

#### 화면별 데이터 소스

| 화면 | 데이터 | 소스 | 정합성 요구 |
|------|--------|------|-------------|
| 경매 상세 | 현재가, 내 순위, 1/2순위 여부 | Redis | **실시간 필수** |
| 내 거래 목록 | 입찰 이력, 내 최고 입찰가 | RDB | Eventual OK |
| 마이페이지 | 거래 통계 | RDB | Eventual OK |

#### Redis 저장 구조 (bid.lua)

```
auction:{id} (Hash)
├── currentPrice      # 현재가
├── topBidderId       # 1순위 입찰자 ID
├── topBidAmount      # 1순위 입찰 금액
├── secondBidderId    # 2순위 입찰자 ID
├── secondBidAmount   # 2순위 입찰 금액
└── ...
```

- 상위 2명의 입찰 정보를 Redis에 저장
- 경매 상세 페이지에서 "내가 1순위인지" 실시간 확인 가능

#### 결론

- **실시간 필요한 정보**: Redis에서 조회 → RDB 동기화와 무관
- **이력/통계 정보**: RDB에서 조회 → 수 초~분 지연 허용
- RDB 동기화 지연이 **사용자 UX에 영향 없음**

---

---

## 예상 vs 현실 (테스트 후 작성 예정)

> 이 섹션은 테스트 실행 후 "계획과 달랐던 점"을 기록할 공간입니다.

| 항목 | 예상 | 실제 | 배운 점 |
|------|------|------|---------|
| TBD | - | - | - |

---

## 변경 이력

| 날짜 | 버전 | 변경 내용 |
|------|------|----------|
| 2026-01-31 | 1.0 | 스펙 인터뷰 기반 초안 작성 |
| 2026-02-05 | 1.1 | 계획 문서임을 명시, 예상vs현실 섹션 추가 |
